---
layout: pilot
title: Measurement
order: 4
next-url: /blueprint
next-title: The Rami Method Blueprint
---

<section>
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <h2><em>How can we measure the performance of the campaign? What does data tell us about which bits and pieces are the most effective?</em></h2>
        <h1>What did we do?</h1>
        <p>We chose to track metrics that will tell us how many people our campaigns reached, if our content successfully engaged the target audience, and what were the most and least successful elements of our experiment. There aren’t a lot of similar metrics that we can compare and contrast our data with: we hope that by sharing our results, we will encourage others to also do so, and will lead to others sharing similar data, building benchmarks, and sharing best practices to optimize campaigns.</p>
        <p>We used campaign metrics provided by AdWords, and Youtube Analytics, along with third party research vendor Tubular Labs who were offering methodologies to measure impact by looking at the public comments under the YouTube videos included in the campaign. We used metrics to answer four simple questions:</p>
        <ul>
          <li><strong>How many people from our target audience did the campaigns reach?</strong> These are called Reach metrics.</li>
          <li><strong>Did they watch the videos, and engage with the playlists?</strong> These are called Engagement metrics and they help us understand if we managed to make our campaign relevant and engaging for the target audience, or if they just glanced over it and moved on to other online activities.</li>
          <li><strong>What did people think about the content?</strong> That’s obviously the hardest question to answer, but we assumed that the comments under the video would give us a clue or two about people’s reactions to the videos.</li>
          <li>
            <strong>What were the better performing elements of our campaign?</strong> What worked best, what didn’t? We also used these analytics to build best practices and refine our experiment and methodology.
          </li>
        </ul>
        <img src="img/rami_illustration_campaignengagment-01.svg" class="img-responsive">
        <h1>What did we learn?</h1>
        <p><strong class="text-uppercase">REACH |</strong> We chose to gauge the reach of our campaigns by the number of unique users who ‘clicked’ on the ads, not just ‘saw’ them. The campaigns reached 440,000 Estimated Unique Users who chose to click on our ads across the different touchpoints of the campaign: Search, Google Display Network. Est. 243,924 unique clickers from the Arabic campaign, and 194,371 unique clickers from the English campaign</p>
        <p><strong class="text-uppercase">ENGAGEMENT |</strong> Click Through Rate is one of the most widely used online advertising metrics to gauge campaigns’ engagement. It’s a ratio showing how often people who see an ad end up clicking it. Given the niche objective of our campaigns, Advocacy is the closest sector we could find to benchmark our campaigns type against. Wordstream reports that for Avg. CTR for Advocacy Search campaigns is 1.72%, and 0.52% Avg. CTR for Advocacy Google Display Network Campaigns.</p>
        <img src="img/rami_illustration_data-01.svg" class="img-responsive">
        <p><strong class="text-uppercase">DATA |</strong> What did this data teach us about our methodology? We reached our target audience! Lessons learned about optimization:<br>
        Lessons learned about keywords: stronger CTR for lower down the funnel<br>
        Lessons learned about narratives: better avg. time in playlist</p>
      </div>
    </div>
  </div>
</section>